{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b4427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clearml import Dataset, Logger, OutputModel, Task\n",
    "\n",
    "task = Task.init(\n",
    "    project_name=\"Amazon reviews\",\n",
    "    task_name=\"TF-IDF Vectorize BernoulliNB\",\n",
    "    output_uri=True,\n",
    ")\n",
    "logger: Logger = task.get_logger()\n",
    "output_model = OutputModel(task=task, framework=\"scikit-learn\")\n",
    "args = {\n",
    "    \"dataset_name\": \"Amazon reviews dataset\",\n",
    "    \"dataset_project\": \"Amazon reviews\",\n",
    "    \"train_dataset_version\": \"1.2.2\",\n",
    "    \"test_dataset_version\": \"1.2.3\",\n",
    "    \"dataset_version\": \"1.2.4\",\n",
    "    \"random_state\": 42,\n",
    "    \"max_features\": 1000,\n",
    "    \"analyzer\": \"word\",\n",
    "}\n",
    "task.connect(args)\n",
    "print(args)\n",
    "train_dataset = Dataset.get(\n",
    "    dataset_name=args[\"dataset_name\"],\n",
    "    dataset_project=args[\"dataset_project\"],\n",
    "    dataset_version=args[\"train_dataset_version\"],\n",
    ")\n",
    "test_dataset = Dataset.get(\n",
    "    dataset_name=args[\"dataset_name\"],\n",
    "    dataset_project=args[\"dataset_project\"],\n",
    "    dataset_version=args[\"test_dataset_version\"],\n",
    ")\n",
    "dataset = Dataset.create(\n",
    "    dataset_name=args[\"dataset_name\"],\n",
    "    dataset_project=args[\"dataset_project\"],\n",
    "    dataset_version=args[\"dataset_version\"],\n",
    "    parent_datasets=[train_dataset, test_dataset],\n",
    ")\n",
    "dataset.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b444fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "train_df = (\n",
    "    pl.read_parquet(Path(dataset.get_local_copy()) / \"processed_train.parquet\")\n",
    "    .with_columns(pl.col(\"corpus\").list.join(\" \"))\n",
    "    .drop(\"index\")\n",
    ")\n",
    "test_df = (\n",
    "    pl.read_parquet(Path(dataset.get_local_copy()) / \"processed_test.parquet\")\n",
    "    .with_columns(pl.col(\"corpus\").list.join(\" \"))\n",
    "    .drop(\"index\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dbdfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"tfidf\",\n",
    "            TfidfVectorizer(\n",
    "                max_features=args[\"max_features\"],\n",
    "                analyzer=args[\"analyzer\"],\n",
    "            ),\n",
    "        ),\n",
    "        (\"bernoulli\", BernoulliNB()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_x, train_y = (\n",
    "    train_df.drop(\"Polarity\").to_pandas(),\n",
    "    train_df.to_pandas()[\"Polarity\"],\n",
    ")\n",
    "test_x, test_y = (\n",
    "    test_df.drop(\"Polarity\").to_pandas(),\n",
    "    test_df.to_pandas()[\"Polarity\"],\n",
    ")\n",
    "\n",
    "pipe.fit(train_x[\"corpus\"], train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464401b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(pipe, \"model.pkl\", compress=True)\n",
    "output_model.update_weights(weights_filename=\"model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f21cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "pred_y = pipe.predict(test_x[\"corpus\"])\n",
    "classification_report_table = pd.DataFrame(\n",
    "    classification_report(test_y, pred_y, output_dict=True)\n",
    ").T\n",
    "logger.report_table(\n",
    "    \"Classifiacation Report\", \"Metrics\", table_plot=classification_report_table\n",
    ")\n",
    "output_model.report_table(\n",
    "    \"Classifiacation Report\", \"Metrics\", table_plot=classification_report_table\n",
    ")\n",
    "classification_report_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ed6f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_y, pred_y, labels=[1, 2])\n",
    "logger.report_confusion_matrix(\"Classifiacation Report\", \"ConflusionMatrix\", cm)\n",
    "output_model.report_confusion_matrix(\"Classifiacation Report\", \"ConflusionMatrix\", cm)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb31fee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "task.mark_completed()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
